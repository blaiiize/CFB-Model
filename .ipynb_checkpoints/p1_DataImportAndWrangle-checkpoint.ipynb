{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b49b25-e267-4ed0-ac59-91adbb444dfa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ee3463-bc89-44ee-b814-3e335dc20998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db84d29d-ea35-4e93-a2d6-96c8d70bd5e9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25658315-aec6-4752-b58c-eaed93f55c11",
   "metadata": {},
   "source": [
    "Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed1182-0efd-42c9-95b1-0a16147332ae",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Downloading individual game data from collegefootballdata.com for years 2004 - 2023 (excluding 2020)\n",
    "Only run this if the data isn't already downloaded, as it takes awhile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ba81a-cf49-4e89-9f0a-795a74456852",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# will take ~1 hour to run\n",
    "\n",
    "# setting the download directory and Chrome settings\n",
    "directory = \"/Users/blaizelahman/Desktop/CFBData\"\n",
    "chromeOptions = webdriver.ChromeOptions()\n",
    "prefs = {\"download.default_directory\": directory}\n",
    "chromeOptions.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "# creating Chrome driver\n",
    "driver = webdriver.Chrome(service = Service(ChromeDriverManager().install()), options = chromeOptions)\n",
    "\n",
    "# dictionary to store game data\n",
    "allWeeksDict = {}\n",
    "\n",
    "# downloading weekly data files for years 2004-2023 from collegefootballdata.com\n",
    "for year in range(2004, 2024):\n",
    "\n",
    "    # skipping 2020 because it has bad data\n",
    "    if year == 2020: \n",
    "        continue\n",
    "        \n",
    "    for week in range(1, 15):\n",
    "        \n",
    "        try:\n",
    "            url = f'https://collegefootballdata.com/exporter/games/teams?year={year}&week={week}&seasonType=regular&excludeGarbageTime=false'\n",
    "            driver.get(url)\n",
    "            time.sleep(3) \n",
    "            \n",
    "            # clicking the query button\n",
    "            query = driver.find_element(By.XPATH, \"//button[contains(span/text(), 'Query')]\")\n",
    "            query.click()\n",
    "            time.sleep(2) \n",
    "            \n",
    "            # clicking the export button\n",
    "            export = driver.find_element(By.XPATH, \"//button[contains(span/text(), 'Export')]\")\n",
    "            export.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "            key = f\"cfb{year}w0{week}\"\n",
    "            \n",
    "            # grabs files from CFBData folder\n",
    "            files = os.listdir(directory)\n",
    "\n",
    "            # grab the file paths for all files ending in .csv\n",
    "            filePaths = [os.path.join(directory, name) for name in files if name.endswith('.csv')]\n",
    "\n",
    "            # grabbing the most recently made file out of those in paths\n",
    "            file = max(filePaths, key=os.path.getctime)\n",
    "            \n",
    "            # loading csv file\n",
    "            allWeeksDict[key] = pd.read_csv(file)\n",
    "\n",
    "            # deleting the file after it has been added\n",
    "            os.remove(file)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Cannot grab data for {year} Week {week}. Error: {e}')\n",
    "\n",
    "    print(f'Successfully grabbed data for {year}')\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac6284c-442f-46fe-81c0-a881048e6536",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Adding Week and Year columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49c54a8-3c10-44b6-88fe-dd97d68513b4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating a week column to display what week it is, also removes the redundant \n",
    "# first row of column names\n",
    "for name, df in allWeeksDict.items():\n",
    "    \n",
    "    # extracts what week it is from the dataframe by getting the last two characters in the name\n",
    "    week_number = name[-2:]\n",
    "    \n",
    "    # converts last two characters into an int\n",
    "    week_number = int(week_number)\n",
    "\n",
    "    # creates new week column that displays the week the game took place\n",
    "    df['Week'] = f\"Week {week_number}\"\n",
    "\n",
    "    # checks what year is being shown in the dataframe and displays it in a year column\n",
    "    year = name[3:7]\n",
    "\n",
    "    df['Year'] = year\n",
    "\n",
    "    # drops the redundant first row and resets the indices of the datadrame\n",
    "    df.drop(0, inplace = True)\n",
    "\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "\n",
    "    # updates dataframe\n",
    "    allWeeksDict[name] = df  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b874f-abbf-4666-9c38-548c1ad0d1fb",
   "metadata": {},
   "source": [
    "Combining all dataframes into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eac32f-c73c-4c0a-8fb5-576d913be414",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "totalWeeklyData = pd.concat(allWeeksDict)\n",
    "\n",
    "# dropping the extra index level that has the name of the original dataframes\n",
    "totalWeeklyData.reset_index(level = 0, drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb90779-f932-41da-9052-216531a78fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalWeeklyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de174ae4-d366-491a-8cee-3a413800a412",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "totalWeeklyData.rename(columns = {0: 'Game Id', 1: 'School', 2: 'Conference', \n",
    "                                  3: 'HomeAway', 4: 'Points', 5: 'Stat Category', 6: 'Stat'}, inplace = True)\n",
    "totalWeeklyData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e802f3b5-f8a9-484b-8eec-c38304de1e0c",
   "metadata": {},
   "source": [
    "Finding non-numeric stat categories that need to be cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed633fe-633e-44f8-8450-e522b93dc772",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# making a copy of the dataframe to look for non-numeric values\n",
    "totalWeeklyDataCopy = totalWeeklyData.copy(deep = True)\n",
    "\n",
    "# converting string type data points to numerics\n",
    "totalWeeklyDataCopy['Stat'] = pd.to_numeric(totalWeeklyDataCopy['Stat'], errors='coerce')\n",
    "\n",
    "# filter out unique non-numeric rows\n",
    "nan_stats = totalWeeklyDataCopy[totalWeeklyDataCopy['Stat'].isna()]['Stat Category'].unique()\n",
    "nan_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9db143-dee7-4a36-8c8e-7987a2b126d6",
   "metadata": {},
   "source": [
    "Converting non-numeric data to numeric interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45b0db0-2dd4-40fd-9f42-5b9b1bb402d8",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replacing the \"-\" in totalPenaltiesYards, completionAttempts, fourthDownEff, and thirdDownEff\n",
    "# with \".\", and the same with \":\" in possessionTime so they can be converted to numeric values\n",
    "totalWeeklyData['Stat'] = totalWeeklyData['Stat'].str.replace('-', '.')\n",
    "totalWeeklyData['Stat'] = totalWeeklyData['Stat'].str.replace(':', '.')\n",
    "\n",
    "totalWeeklyData['Stat'] = pd.to_numeric(totalWeeklyData['Stat'], errors = 'coerce')\n",
    "totalWeeklyData\n",
    "\n",
    "# converting points to numerics\n",
    "totalWeeklyData['Points'] = pd.to_numeric(totalWeeklyData['Points'], errors = 'coerce')\n",
    "totalWeeklyData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc910ba7-c747-4b45-b8ae-d2dd3689c8b1",
   "metadata": {},
   "source": [
    "Pivoting the dataframe wider so that each stat category has its own column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b7ba7b-6593-4ba1-9a9d-a992badfd47b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting the amount of games in the dataframe before pivoting to compare to after\n",
    "prePivotedIds = totalWeeklyData['Game Id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247194fc-e678-42cd-a687-7d5cd0b209bc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pivoting the Stat Category column into multiple columns each with their respective stat\n",
    "totalWeeklyData = totalWeeklyData.pivot(index=['Game Id', 'School', 'Conference', 'HomeAway', 'Points', 'Week', 'Year'], \n",
    "                      columns='Stat Category', \n",
    "                      values='Stat').reset_index()\n",
    "\n",
    "# flattening the columns\n",
    "totalWeeklyData.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in totalWeeklyData.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7372ad1e-3f32-4d9d-b509-a5faf52af1de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "totalWeeklyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8aecfc-16e0-4e35-9ae0-27c9b16d3324",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting the amount of games in the newly pivoted dataframe and ensuring that no game data was lost\n",
    "pivotedIDs = totalWeeklyData['Game Id'].unique()\n",
    "print(len(prePivotedIds) == len(pivotedIDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205c3bb5-f221-4b6b-8a68-fbaadaf7ca90",
   "metadata": {},
   "source": [
    "Making a custom rolling sum function that skips NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571ee443-0166-4a3c-b56f-04d6f643af38",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def customRollingSum(column, window):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for i in range(len(column)):\n",
    "        \n",
    "        if i < window - 1:\n",
    "            result.append(np.nan)\n",
    "            \n",
    "        else:\n",
    "            result.append(column[i - window:i].sum(skipna = True))\n",
    "            \n",
    "    return pd.Series(result, index = column.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e4fe19-0b70-4358-9a98-624a1312f9b0",
   "metadata": {},
   "source": [
    "Making a function to grab an individual team's game data and their opponent's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db39c164-6991-4aff-bab6-d7ddf81486d4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def createTeam(team):\n",
    "\n",
    "    # getting rid of redundant error warning\n",
    "    pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "    # getting all games with the given team\n",
    "    teamGames = totalWeeklyData[totalWeeklyData['School'] == team]\n",
    "    gameIDs = teamGames['Game Id'].unique()\n",
    "    \n",
    "    # adding in all opponents of the given team and their stats\n",
    "    teamDF = totalWeeklyData[totalWeeklyData['Game Id'].isin(gameIDs)]\n",
    "\n",
    "    # converting the week column to an int so the dataframe can then be sorted by year and week\n",
    "    teamDF['Week'] = teamDF['Week'].str[-2:].astype(int)\n",
    "    teamDF = teamDF.sort_values(by = [\"Year\", \"Week\"])\n",
    "\n",
    "    teamDF = teamDF.reset_index(drop=True)\n",
    "\n",
    "    # adding a total touchdown column\n",
    "    teamDF['totalTDs'] = teamDF[['passingTDs', 'rushingTDs', 'interceptionTDs', 'kickReturnTDs', 'puntReturnTDs']].sum(axis = 1, skipna = True)\n",
    "\n",
    "    # merging dataframe to pair teams who played each other by Game Id and differentiating the opponent's stats\n",
    "    mergeTeamDF = teamDF.merge(teamDF, on='Game Id', suffixes=('', '_opp'))\n",
    "\n",
    "    # making sure there's no duplicates\n",
    "    mergeTeamDF = mergeTeamDF[mergeTeamDF['School'] != mergeTeamDF['School_opp']]\n",
    "\n",
    "    # getting score differentials and point totals\n",
    "    mergeTeamDF['scoreDiff'] = mergeTeamDF['Points'] - mergeTeamDF['Points_opp']\n",
    "    mergeTeamDF['pointTotal'] = mergeTeamDF['Points'] + mergeTeamDF['Points_opp']\n",
    "\n",
    "    # adding a win column to show if the given team won a game or not\n",
    "    mergeTeamDF['Win'] = mergeTeamDF['scoreDiff'] > 0\n",
    "\n",
    "    # setting the dataframe to the merged version\n",
    "    teamDF = mergeTeamDF\n",
    "\n",
    "    teamDF = teamDF[teamDF['School'] == team]\n",
    "    \n",
    "    # making rolling sum columns for selected stats for the past 20 and 8 games  \n",
    "    for games in [20, 8]:\n",
    "        for column in ['Points','firstDowns','fumblesLost','fumblesRecovered','interceptions','kickReturnYards','kickingPoints','netPassingYards',\n",
    "                      'passesDeflected', 'passesIntercepted','passingTDs','puntReturns','qbHurries','rushingAttempts','rushingTDs','rushingYards',\n",
    "                       'sacks','tacklesForLoss','totalFumbles','totalPenaltiesYards','totalYards','turnovers','yardsPerPass','yardsPerRushAttempt', 'totalTDs']:\n",
    "            newColumn = 'rolling_sum_' + column + str(games) \n",
    "            teamDF[newColumn] = customRollingSum(teamDF[column], games)\n",
    "            \n",
    "    # altering yardsPerPass and yardsPerRushAttempt columns to reflect their values over the past 20 and 8 games\n",
    "    teamDF['rolling_sum_yardsPerPass20'] = teamDF['rolling_sum_yardsPerPass20'] / 20\n",
    "    teamDF['rolling_sum_yardsPerPass8'] = teamDF['rolling_sum_yardsPerPass8'] / 8\n",
    "\n",
    "    teamDF['rolling_sum_yardsPerRushAttempt20'] = teamDF['rolling_sum_yardsPerRushAttempt20'] / 20\n",
    "    teamDF['rolling_sum_yardsPerRushAttempt8'] = teamDF['rolling_sum_yardsPerRushAttempt8'] / 8\n",
    "    \n",
    "    return teamDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98940187-3759-4cf0-9e70-ad81c428d57c",
   "metadata": {},
   "source": [
    "Creating a dictionary of every team's dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d7cad4-a320-4481-a959-9ddb273a63b1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tempDict = {}\n",
    "for team in totalWeeklyData.School.unique():\n",
    "    dfName = f'temp_{team}'\n",
    "    tempDict[dfName] = createTeam(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8b7233-1294-42a7-8c04-bcd39b1845bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "FSU = tempDict['temp_Florida State']\n",
    "FSU.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a8cb45-99e0-43c4-a3c2-67ac7501a48e",
   "metadata": {},
   "source": [
    "Making a function to merge the opponent's rolling sum stats at the time of the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068f721-33b8-4662-8fd9-e247a85f2c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeRollingSum(team):\n",
    "\n",
    "    # making a copy of the teams dataframe from tempDict\n",
    "    teamDF = tempDict[team].copy() \n",
    "\n",
    "    # going through the dataframe and merging the opponent's rolling_sum columns row by row\n",
    "    for index, row in teamDF.iterrows():\n",
    "\n",
    "        # grabbing gameIds and each opponent's name to access their dataframes in tempDict\n",
    "        gameID = row['Game Id']\n",
    "        oppName = 'temp_' + row['School_opp']\n",
    "        \n",
    "        oppDF = tempDict[oppName]\n",
    "        \n",
    "        # getting the opponent's rolling_sum columns from the game they played the given team\n",
    "        oppRow = oppDF[oppDF['Game Id'] == gameID]\n",
    "        \n",
    "        rollingCols = [col for col in oppRow.columns if col.startswith('rolling_sum')]\n",
    "\n",
    "        # merging the opponent's rolling_sum columns on the row the team plays them\n",
    "        for col in rollingCols:\n",
    "            teamDF.loc[index, col + '_opp'] = oppRow.iloc[0][col]\n",
    "    \n",
    "    return teamDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b5d04d-5959-4739-a651-e3cb9329c216",
   "metadata": {},
   "source": [
    "Making a dictionary of completed dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d3d5ef-8acb-4d39-afba-8c4bf52f3b27",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "teamDict = {}\n",
    "for team in tempDict.keys():\n",
    "    \n",
    "    updatedDF = mergeRollingSum(team)  \n",
    "    keyName = team[5:]\n",
    "    teamDict[keyName] = updatedDF\n",
    "    print('Added: ' + keyName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0626e36-c9c7-4198-8f02-aa7172dc1817",
   "metadata": {},
   "source": [
    "Inspecting dataframe to see that things look good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9595ba48-2145-44fa-a852-46a6ac282a5f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'teamDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m teamDict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFlorida State\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'teamDict' is not defined"
     ]
    }
   ],
   "source": [
    "teamDict['Florida State']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aee9bf4-c018-4f60-943a-07f4835d0614",
   "metadata": {},
   "source": [
    "We can see that in 2022, our data source labeled the week 0 game as another week 1 game. Let's fix that by swapping it with the actual week 1 game and then changing it to say week 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929d9d8-2d6d-4a1c-b462-b7a685a879f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "teamDict['Florida State'][teamDict['Florida State']['Year'] == 2022][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c10650-a2f8-4201-959e-fc09af5654ac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# going through all teams in the dictionary and correcting any week 0 games\n",
    "for team, teamDF in teamDict.items():\n",
    "    \n",
    "    for year in np.unique(teamDF['Year'].values):\n",
    "\n",
    "        yearDF = teamDF[teamDF['Year'] == year]\n",
    "\n",
    "        # checks if there's two week 1's\n",
    "        if np.sum(yearDF['Week'].values == 1) > 1:\n",
    "\n",
    "            # swapping week 0 and week 1 because the actual week 1 game is before the week 0 game\n",
    "            teamWeek0 = yearDF.index[0]\n",
    "            teamWeek1 = yearDF.index[1]\n",
    "\n",
    "            teamDF.loc[teamWeek0], teamDF.loc[teamWeek1] = teamDF.loc[teamWeek1].copy(), teamDF.loc[teamWeek0].copy()\n",
    "\n",
    "            # setting the week 0 game to say week 0\n",
    "            teamDF.at[teamWeek0, 'Week'] = 0\n",
    "            \n",
    "            print(f'Added week 0 for {team} in year {year}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1a995e-5d92-4c06-8f15-38d950314927",
   "metadata": {},
   "outputs": [],
   "source": [
    "teamDict['Florida State'][teamDict['Florida State']['Year'] == 2022][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127deb95-89f4-48f3-8d0a-d3a801518aca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now that it's fixed, we're ready to save our csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ef48ed-9b37-434b-b733-62a92b2ecaf8",
   "metadata": {},
   "source": [
    "Creating csv's for all current teams to be used for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e66c9-6c77-489b-85c7-f74e5e14673c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key, team in teamDict.items():\n",
    "    if '2023' in team['Year'].values:\n",
    "        name = key.replace(' ', '_') + '_model.csv'\n",
    "        team.to_csv(name)\n",
    "        print('CSV: ' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cdd451-6e89-4a13-ad50-791095aecc94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
